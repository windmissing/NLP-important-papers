https://arxiv.org/pdf/1508.06576.pdf?translate=1&translate=1&translate=1&translate=1

在美术特别是绘画中，人类已经掌握了通过在图像的内容和样式之间进行复杂的相互作用来创造独特视觉体验的技巧。到目前为止，该过程的算法基础是未知的，并且不存在具有类似功能的人工系统。但是，在最近的一些关键的视觉感知领域中，例如物体和面部识别，近乎人类的表现已通过一类名为“深层神经网络”的生物启发式视觉模型得到证明。1、2这里，我们介绍了一种基于深层神经网络的人工系统，该系统可以创建高感知质量的艺术形象。该系统使用神经表示来分离和重新组合任意图像的内容和样式，从而为创建艺术图像提供了一种神经算法。此外，鉴于性能优化的人工神经网络与生物视觉之间的惊人相似性，3-7我们的工作为人们如何创造和感知艺术意象提供了一种算法上的理解。

在图像处理任务中功能最强大的一类深度神经网络称为卷积神经网络。 卷积神经网络由小型计算单元组成，这些单元以前馈方式对视觉信息进行分层处理（图1）。 每个单元层都可以理解为图像滤镜的集合，每个滤镜都从输入图像中提取特定特征。 因此，给定层的输出由所谓的特征图组成：输入图像的不同滤波版本。

当对卷积神经网络进行对象识别训练时，它们会形成图像的表示形式，从而使对象信息沿处理层次结构逐渐变得清晰。8因此，沿着网络的处理层次结构，输入图像被转换为​​越来越关心图像的表示形式。图片的实际内容与其详细像素值的比较。通过仅从该图层9中的特征图重建图像，我们可以直接可视化每一层包含的有关输入图像的信息（图1，内容重建，有关如何重建图像的详细信息，请参见方法）。网络中的更高层捕获对象及其在输入图像中的排列方面的高级内容，但不限制重构的确切像素值。 （图1，内容重建d，e）。相比之下，从较低层进行的重建仅可以再现原始图像的精确像素值（图1，内容重建sa，b，c）。因此，我们将网络高层中的特征响应称为内容表示。

为了获得输入图像样式的表示，我们使用最初设计为捕获纹理信息的特征空间。8该特征空间建立在网络每一层的过滤器响应之上。 它由特征图的空间范围内不同滤波器响应之间的相关性组成（有关详细信息，请参见方法）。 通过包括多层的特征相关性，我们获得了输入图像的平稳，多尺度表示，该图像捕获其纹理信息，但不捕获其整体布置。

再次，我们可以通过构建与给定输入图像的样式表示相匹配的图像，来可视化在网络的不同层上构建的这些样式特征空间所捕获的信息（图1，样式重构）。10，11样式特征的实际重构会生成纹理化版本 捕获其颜色和局部结构的一般外观的输入图像。 此外，来自输入图像的局部图像结构的大小和复杂度沿着层次结构增加，这一结果可以通过增加的接收场大小和特征复杂度来解释。 我们将这种多尺度表示形式称为样式表示。

本文的主要发现是卷积神经网络中内容和样式的表示是可分离的。 也就是说，我们可以独立地操纵这两种表示以产生新的，具有感知意义的图像。 为了证明这一发现，我们生成了混合了来自两个不同源图像的内容和样式表示的图像。特别是，我们匹配了描绘德国图宾根州“ Neckarfront”的照片的内容表示以及一些知名的样式表示 来自不同时期的艺术品（图2）。

通过找到同时匹配照片的内容表示和相应艺术品的样式表示的图像来合成图像（有关详细信息，请参见方法）。 在保留原始照片的全局布局的同时，由艺术品提供构成全局风景的颜色和局部结构。有效地，这使照片呈现出艺术品的风格，从而使合成图像的外观与作品相似 即使它显示的内容与照片相同。

如上所述，样式表示是一种多尺度表示，其中包括神经网络的多个层。 在图2中所示的图像中，样式表示包括整个网络层次结构中的图层。 通过仅包含较少数量的较低层，也可以更局部地定义样式，从而导致不同的视觉体验（图3，沿行）。 当将样式表示匹配到网络中的更高层时，本地图像结构将以越来越大的比例进行匹配，从而带来更流畅，更连续的视觉体验。 因此，通常通过将样式表示匹配到网络中的最高层来创建视觉上最吸引人的图像（图3，lastrow）。

当然，图像内容和样式不能完全解开。当合成将​​一个图像的内容与另一个图像的样式结合在一起的图像时，通常不存在同时完美匹配两个约束的图像。但是，我们在图像合成过程中最小化的损失函数分别包含两个术语，分别代表内容和样式，两者相距很远（请参见方法）。因此，我们可以在重建内容或样式上平稳地调整重点（图3，沿列）。强调风格会产生与艺术品外观相匹配的图像，有效地赋予其纹理化版本，但几乎不显示照片的任何内容（图3，第一列）。在强调内容时，可以清楚地识别照片，但是绘画的风格并不那么匹配（图3，最后一栏）。对于特定的一对源图像，可以调整内容和样式之间的权衡以创建视觉上吸引人的图像。

在这里，我们提出了一种人工神经系统，该系统实现了图像内容与样式的分离，从而允许以任何其他图像的样式重铸一个图像的内容。 通过创建新的艺术图像来说明这一点，这些图像将几种知名绘画的风格与随意选择的照片的内容相结合。 特别是，我们从经过对象识别训练的高性能深度神经网络的特征响应中得出图像内容和样式的神经表示。 据我们所知，这是图像特征的首次展示，该图像特征将内容与风格从整个自然图像中分离出来。

以前将内容从样式中分离出来的工作是根据复杂程度要低得多的感官输入进行评估的，例如不同笔迹中的字符或面部图像或姿势不大的小人物图像。12，13

在我们的演示中，我们以一系列知名艺术品的风格渲染给定的照片。 通常在称为非照片级渲染的计算机视觉分支中解决此问题（有关最新评论，请参见14）。 从概念上讲，最密切相关的是使用纹理转移实现艺术风格转移的方法。15-19然而，这些先前的方法主要依靠非参数技术来直接操纵图像的像素表示。 相反，通过使用经过对象识别训练的深度神经网络，我们可以在特征空间中进行操作，以明确表示图像的高级内容。

之前已经将深度神经网络中经过对象识别训练的功能用于样式识别，以便根据作品的创作时间对艺术品进行分类。20在那里，分类器在原始网络激活的基础上进行训练，我们称之为内容表示。 我们推测，向固定特征空间（如样式表示）的转换可能会在样式分类中实现更好的性能。

总的来说，我们合成来自不同来源的内容和样式的图像的合成方法，为研究艺术，样式和与内容无关的图像外观的感知和神经表示提供了一种新颖而有趣的工具。我们可以设计新颖的刺激，引入两个独立的，在感知上有意义的变异来源：图像的外观和内容。我们预想这对于从视觉物理学到功能成像甚至是电生理神经记录的关于视觉感知的广泛实验研究都是有用的。实际上，我们的工作为神经表示如何独立捕获图像内容及其呈现方式提供了算法上的理解。重要的是，我们的样式表示形式的数学形式产生了一个清晰的，可检验的假说，即关于图像外观到单个神经元水平的表示形式。样式表示仅计算网络中不同类型神经元之间的相关性。提取神经元之间的相关性是一种生物学上合理的计算，例如由初级视觉系统（V1）中的所谓复杂细胞实现。21我们的结果表明，在腹侧流的不同处理阶段执行类似复杂细胞的计算将是获得视觉输入外观的内容无关表示的一种可能方式。

总而言之，神经系统经过训练可以执行生物视觉的核心计算任务之一，它会自动学习图像表示形式，从而使图像内容与样式分离，这确实令人着迷。 可能的解释是，当学习对象识别时，网络必须对所有保留对象身份的图像变化保持不变。 将图像内容的变化及其外观变化分解为因子的表示对于此任务将是非常实用的。 因此，我们从样式中提取内容的能力以及因此我们创造和享受艺术的能力可能主要是视觉系统强大推断能力的杰出标志。

# Methods

正文中给出的结果是在VGG网络22的基础上生成的，该神经网络在一个常见的视觉对象识别基准任务23上可与人类表现相媲美，并在22中进行了介绍和广泛描述。 19层VGG网络的5个池化层。 我们不使用任何完全连接的层。该模型是可公开获得的，可以在caffe框架中进行探索。24对于图像合成，我们发现用平均池代替最大池操作可以改善梯度流，并且可以获得稍微更吸引人的结果， 这就是为什么显示的图像是通过平均池生成的。

通常，网络中的每个层都定义了一个非线性滤波器组，其复杂度随网络中该层的位置而增加。 因此，给定的输入图像x通过过滤器对该图像的响应被编码在CNN的每一层中。 具有N1个不同过滤器的图层会映射每个大小为M1的特征，其中Ml是feature map的高度乘以宽度。因此，图层1中的响应可以存储在矩阵F1 RN1×M1中，其中F1ij是激活在位置jin处的第一个过滤器。 为了可视化在层次结构的不同层上编码的图像信息（图1，内容重建），我们在白噪声图像上执行梯度下降以找到与原始图像的特征响应匹配的另一幅图像。 因此，分别定义原始图像和生成的图像为p和x，$P^l$和$F^l$分别是它们在图层1中中的显示特征。 然后我们定义两个特征表示之间的平方误差损失

$$
L_{\text{content}}(p, x, l) = \frac{1}{2}\sum_{i,j}(F^l_{ij} - P^l_{ij})^2
$$

关于l层激活的这种损失的导数  

$$
\frac{\partial L_{\text{content}}}{\partial F^l_{ij}} = 
\begin{cases}
(F^l - P^l)_{ij}, && F^l_{ij}>0 \\
0, && F^l_{ij}<0 
\end{cases}
$$

从中可以使用标准误差反向传播来计算相对于图像x的梯度。 因此，我们可以更改初始随机图像，直到它在CNN的特定层中产生与原始图像相同的响应。 图1中的五个内容重构来自原始VGG网络的“ conv11”（a），“ conv21”（b），“ conv31”（c），“ conv41”（d）和“ conv51”（e）层。

在网络各层的CNN响应之上，我们构建了一种样式表示形式，用于计算不同过滤器响应之间的相关性，其中对输入图像的空间范围进行预期。 这些特征相关性由Gram矩阵$G^l \in R^{N_l \times N_l}$给出，其中$G^l_{ij}$ 是层l中矢量化特征图i和j之间的内积  

$$
G^l_{ij} = \sum_k F^l_{ij}F^l_{ij}
$$

为了生成与给定图像样式匹配的纹理（图1，样式重建），我们使用白噪声图像的梯度下降来找到与原始图像样式表示匹配的另一幅图像。 这是通过使原始图像的Gram矩阵的条目与要生成的图像的Gram矩阵之间的均方距离最小来完成的。 因此，让a和x分别为原始图像和生成的图像，以及$A^l$和$G^l$各自在图层1中的样式表示。 则该层对总损耗的贡献为  

$$
E_l = \frac{1}{4N^2_lM^2_l}\sum_{i,j}(G^l_{ij}-A^l_{ij})^2
$$

总损失是

$$
L_{\text{style}}(a, x) = \sum_l w_l E_l
$$

其中$w_l$原来各层对总损耗的贡献的加权因子（请参见下文了解我们结果的具体值）。 $E_l$关于层1中的激活的导数可以解析地计算：  

$$
\frac{\partial E_l}{\partial F^l_{ij}} = 
\begin{cases}
\frac{1}{N^2_lM^2_l((F^l)^\top(G^l - A^l))}, && F^l_{ij} > 0 \\
0, && F^l_{ij} < 0
\end{cases}
$$

使用标准误差反向传播，可以容易地计算出El相对于网络较低层中的激活的梯度。 图1中的五个样式重构是通过匹配图层'conv11'（a），'conv11'和'conv21'（b），'conv11'，'conv21'和'conv31'（c），'conv11 '，'conv21'，'conv31'和'conv41'（d），'conv11'，'conv21'，'conv31'，'conv41'和'conv51'（e）。

为了生成将照片内容与绘画风格混合在一起的图像（图2），我们共同最小化了白噪声图像与内容表示的距离在网络的一层中显示照片的样式，并在CNN的许多层中显示绘画的样式。 因此，让照片成为艺术品。 我们最小化的损失函数是

$$
L_{\text{total}}(p, a, x) = \alpha L_{\text{content}}(p, x) + \beta L_{\text{style}}(a, x)
$$

在网络的一层中显示照片的样式，并在CNN的许多层中显示绘画的样式。因此，让照片成为艺术品。我们将损失函数最小化为Ltotal（〜p，〜a，〜x）=αLcontent（〜p，〜x）+βLstyle（〜a，〜x）（7），其中α和β分别是内容和样式重构的权重因子。对于图2所示的图像，我们匹配了'conv42'层上的内容表示和'conv11'，'conv21'，'conv31'，'conv41'和'conv51'上的样式表示（在这些层中wl = 1/5，wl在所有其他层中= 0）。 α/β的比值是1×10-3（图2 B，C，D）或1×10-4（图2 E，F）。图3显示了内容和样式重构损失（沿着列）的不同相对权重以及仅在图层'conv11'（A），'conv11'和'conv21'（B），'conv11'，' conv21'和'conv31'（C），'conv11'，'conv21'，'conv31'和'conv41'（D），'conv11'，'conv21'，'conv31'，'conv41'和'conv51'（E ）。因子wl总是等于1除以具有非零损耗权重wl的有效层数。

其中，α和β分别是内容和样式重构的加权因子。 对于图2所示的图像，我们匹配了'conv42'层上的内容表示和'conv11'，'conv21'，'conv31'，'conv41'和'conv51'上的样式表示（在这些层中wl = 1/5，wl 在所有其他层中= 0）。 α/β的比值为1×10-3（图2 B，C，D）或1×10-4（图2 E，F）。 图3显示了内容和样式重构损失（沿着列）的不同相对权重以及仅在图层'conv11'（A），'conv11'和'conv21'（B），'conv11'，' conv21'和'conv31'（C），'conv11'，'conv21'，'conv31'和'conv41'（D），'conv11'，'conv21'，'conv31'，'conv41'和'conv51'（E ）。 因子wl总是等于1除以具有非零损耗权重wl的有效层数。

**致谢** 这项工作由德国国家学术基金会（L.A.G.），伯恩斯坦计算神经科学中心（FKZ 01GQ1002）和德国人综合素养计划（T.ubingen）综合神经科学中心（EXC307）（M.B.，A.S.E，L.A.G.）资助。
