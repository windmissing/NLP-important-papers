# Paper title

Bilingual Dictionary Based Neural Machine Translation without Using Parallel Sentences

# link

https://www.aclweb.org/anthology/2020.acl-main.143.pdf

# 摘要

In this paper, we propose a new task of machine translation (MT), which is based on no parallel sentences but can refer to a groundtruth bilingual dictionary. Motivated by the ability of a monolingual speaker learning to translate via looking up the bilingual dictionary, we propose the task to see how much potential an MT system can attain using the bilingual dictionary and large scale monolingual corpora, while is independent on parallel sentences. We propose anchored training (AT) to tackle the task. AT uses the bilingual dictionary to establish anchoring points for closing the gap between source language and target language. Experiments on various language pairs show that our approaches are significantly better than various baselines, including dictionary-based word-byword translation, dictionary-supervised crosslingual word embedding transformation, and unsupervised MT. On distant language pairs that are hard for unsupervised MT to perform well, AT performs remarkably better, achieving performances comparable to supervised SMT trained on more than 4M parallel sentences1 .

# 要解决什么问题

不基于parallel sentences而是基于双语字典训练翻译模型。

# 作者的主要贡献

Anchored training(AT)基于双语字典构建anchoring points来实现两种语言之间的转换。

# 得到了什么结果

性能优于baseline。  
在distant language pairs场景中表现特别好。

# 关键字	
