# Paper title

Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation

# link

https://www.aclweb.org/anthology/2020.acl-main.224.pdf

# 摘要

Generating sequential natural language descriptions from graph-structured data (e.g., knowledge graph) is challenging, partly because of the structural differences between the input graph and the output text. Hence, popular sequence-to-sequence models, which require serialized input, are not a natural fit for this task. Graph neural networks, on the other hand, can better encode the input graph but broaden the structural gap between the encoder and decoder, making faithful generation difficult. To narrow this gap, we propose DUALENC, a dual encoding model that can not only incorporate the graph structure, but can also cater to the linear structure of the output text. Empirical comparisons with strong single-encoder baselines demonstrate that dual encoding can significantly improve the quality of the generated text.

# 要解决什么问题

Seq2seq模型的encoder和decoder是相似的，但不能处理图像输入。  
Graph2seq模型可以处理图像输入，但是encoder和decoder的gap比较大。  

# 作者的主要贡献

DUALENC：双向encoding模型，结合图像结构和线性结构。  

# 得到了什么结果

比single-encoder性能好。  

# 关键字