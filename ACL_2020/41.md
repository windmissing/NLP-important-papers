# Paper title

Norm-Based Curriculum Learning for Neural Machine Translation

# link

https://www.aclweb.org/anthology/2020.acl-main.41.pdf

# 摘要

A neural machine translation (NMT) system is expensive to train, especially with highresource settings. As the NMT architectures become deeper and wider, this issue gets worse and worse. In this paper, we aim to improve the efficiency of training an NMT by introducing a novel norm-based curriculum learning method. We use the norm (aka length or module) of a word embedding as a measure of 1) the difficulty of the sentence, 2) the competence of the model, and 3) the weight of the sentence. The normbased sentence difficulty takes the advantages of both linguistically motivated and modelbased sentence difficulties. It is easy to determine and contains learning-dependent features. The norm-based model competence makes NMT learn the curriculum in a fully automated way, while the norm-based sentence weight further enhances the learning of the vector representation of the NMT. Experimental results for the WMT’14 English– German and WMT’17 Chinese–English translation tasks demonstrate that the proposed method outperforms strong baselines in terms of BLEU score (+1.17/+1.56) and training speedup (2.22x/3.33x). 

# 要解决什么问题

当网络变深变宽时，训练NMT非常expensive。

# 作者的主要贡献

引入norm-based curriculum learning method来提升训练的效果。  
计算并基于以下内容制定学习的课程表：  
(1) 句子的难度 （2）模型的能力 （3）句子的权重  
1/2/3是基于word embedding计算的，3又反过来影响embedding  

# 得到了什么结果

WMT 14 English– German     BLEU     +1.17    speedup     2.22x  
WMT17 Chinese–English     BLEU     + 1.56     speedup     3.33x

# 关键字

Encoder，curriculum , efficiency
